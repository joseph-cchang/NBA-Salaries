---
title: "PSTAT131 Final Project"
author: "Joseph Chang, Tom Wei, Akul Bajaj"
date: "3/11/2022"
output:
html_document:
df_print: paged
---

```{r setup, include=FALSE, echo = FALSE}
# set global chunk options: images will be 7x5 inches
knitr::opts_chunk$set(fig.width=7, fig.height=5, echo =TRUE)
options(digits = 4)
```

## packages

```{r}
#install.packages("tidyverse")
#install.packages("corrplot")
#install.packages("ggplot2")       
#install.packages("GGally")
library(ggplot2)                     
library(GGally)
library(tidyverse)
library(glmnet)
library(knitr)
library(dplyr)
library(tidyverse)
library(modelr)
library(pander)
library(corrplot)
library(readxl)
library(ISLR)
library(tidymodels)
library(ggthemes)
library(naniar)
library(ROCR)
```

## read data

```{r}
# this is where we will input the data 

# first dataset
X2020_2021_NBA_Stats_Player_Box_Score_Advanced_Metrics <- read_excel("2020-2021 NBA Stats  Player Box Score  Advanced Metrics.xlsx")

bball_stats <- as.data.frame(X2020_2021_NBA_Stats_Player_Box_Score_Advanced_Metrics)
my_colnames <- c('Rank', 'Player', 'Team', 'Position', 'Age', 'Games.Played', 'MPG', 'Minutes%', 'Usage_Rate' , 'Turnover_rate', 'free_throws_attempted', 'Free_throw_percent', '2-point field goals attempted', '2-point%', '3-point_field_goals attempted', 'three_point_percent', 'effective_shooting %' , 'True_shooting %', 'PPG', 'RPG', 'Total rebound %', 'APG', 'Assist %', 'SPG' ,'BPG', 'TPG', 'Versatility_Index', 'Offensive_Rating' , 'Defensive_Rating')
colnames(bball_stats) <- my_colnames
new_bball_stats <- bball_stats[-1,-1]
new_bball_stats

# second dataset
labels <- c('Player','Position', 'Age', 'Team', 'Games', 'Minutes_played', 'Player_Efficiency_Rating', 'true_shooting_%', '3-point attempt rate', 'free-throw attempt rate', 'offensive rebound percentage', 'defensive rebound percentage', 'total rebound percentage', 'assist percentage', 'steal percentage', 'block percentage', 'turnover percentage', 'usage_rate', 'offensive_win_shares', 'defensive_win_shares', 'win_shares','win shares per 48 minutes', 'Offensive_Box Plus/Minus', 'Defensive_Box Plus/Minus','Box_Plus_Minus','Value_Over_Replacement')
data_advanced <- read.csv("nba2021_advanced.csv", col.names = labels, na= "XXX")
data_advanced

# salaries dataset
labels2 <- c('Rank', 'Player', 'Salary', 'Use', 'Guaranteed')
salaries <- read.csv("nba_salaries_21-22.csv", col.names = labels2)
salaries
```

## Merge data

```{r}
# this is where we merge data
combine <- inner_join(new_bball_stats, data_advanced, by = 'Player') %>% 
  inner_join(salaries, by = 'Player')
  
# cut down all predictors to only 24 predictors
selection <- subset(combine, select= -c(2:4,7,9,10,12:14,20,22,29:33,35:47,49:51,54,56:57))
less_data <- selection %>% relocate(c(PPG,RPG,APG,SPG,BPG,TPG), .before = MPG)
less_data

# Convert predictors in less_data all to dbl, not chr
conversion <- less_data[,2:22] %>% mutate_if(is.character,as.numeric)
conversion1 <- conversion %>% add_column(less_data$Player) 
names(conversion1)[names(conversion1) == "less_data$Player"] <- "Player"
conversion2 <- conversion1 %>% relocate((Player), .before = Games.Played)
conversion2
```

## filter data

```{r}
# filter players with games played over 10, then filter with total minutes played over 100
our_data <- conversion2 %>% filter(Games.Played >= 10 & MPG > 10) %>% select(Player:Salary) %>% drop_na()
our_data
```

## Plot of response variable

```{r}
plot(our_data$Salary, ylab= "Salary", ylim=c(0, 50000000))
hist(our_data$Salary, main = "Histogram of NBA salaries 2021-2022", xlab="Salary Amount",breaks = "Sturges")
```

## Check to see Correlation

```{r}
# correlation to see predictors vs other predictors in our_data2
my_cor <- our_data %>% select_if(is.numeric) %>% drop_na() %>% cor() %>% round(3) 
corrplot(my_cor, method = "circle", type = "upper", cex.pch=10)
```

## Correlation Check Part 2

```{r}
salarycor <- our_data %>% select(Salary,Games.Played,PPG,RPG,APG,SPG,BPG,TPG,MPG,Usage_Rate, Free_throw_percent, three_point_percent,Versatility_Index, Offensive_Rating, Defensive_Rating, win_shares, Box_Plus_Minus, Value_Over_Replacement) %>% drop_na()

#ggpairs(salarycor)
cor(salarycor)[,"Salary"]
```

Based from the correlation, we see that PPG>MPG>TPG>Value.Over.Replacement>APG>win.shares>Versatility Index>Box.Plus.Minus> Usage Rate>RPG>SPG>Free throw%>Offensive Rating>Defensive rating>BPG>Games.Played>three-point %

We will filter those correlations above 0.5, meaning we will only use PPG, MPG, TPG,Value.Over.Replacement, APG, win.shares, Versatility Index, Box.Plus.Minus, Usage Rate.

## training and testing data

```{r}
# Set random seed
set.seed(3112022)

# Sample 80% observations as training data
fit_data <- our_data[-1] 
new_data <- resample_partition(fit_data, p = c(test=0.2, train=0.8)) 
training <- as.data.frame(new_data$train)
testing <- as.data.frame(new_data$test)
```

## Linear regression

```{r}
# linear regression for data

# training data
fit <- lm(Salary ~ PPG + MPG+TPG+Value_Over_Replacement+APG+win_shares+ Versatility_Index+ Box_Plus_Minus + Usage_Rate, data = training)
summary(fit)

# predicted salaries for training
na.omit(training)
train.predict <- predict(fit, training)

# predicted salaries for testing
test.predict <- predict(fit, testing)

# MSE of train/test
mean((train.predict-training$Salary)^2)
mean((test.predict-testing$Salary)^2)


# predictors that have high correlation with Salary (p-value less than 0.05)
fit2 <- lm(Salary ~ PPG + Usage_Rate + APG, data= training)
summary(fit2)

fit3 <- lm(Salary ~ PPG, data= fit_data)
summary(fit3)


```

## Training dataset 80%, testing 20%

## regularized regression

## Logistic regression?
Create a new variable, salarygreater: whether a player's salary is greater than mean 
```{r}
mean_train_salary <- mean(training$Salary)
training_salarymean<- training %>% mutate(salarygreater=factor(ifelse(Salary >= mean_train_salary, 1, 0),
                                                                     levels=c(0, 1)))
training_logit <- glm(salarygreater ~ PPG + MPG+TPG+Value_Over_Replacement+APG+win_shares+ Versatility_Index+ 
                        Box_Plus_Minus + Usage_Rate, data = training_salarymean, family = 'binomial')

#prediction
salarymean_pred_training <- predict(training_logit, training_salarymean, type="response")
train_maj_rule <- ifelse(salarymean_pred_training > 0.5, 1,0)

#testing error
calc_error_rate(train_maj_rule, training_salarymean$salarygreater)

#and do the same with the testing error:
testing_salarymean<- testing %>% mutate(salarygreater=factor(ifelse(Salary >= mean_train_salary, 1, 0),
                                                               levels=c(0, 1)))
salarymean_pred_testing <- predict(training_logit,  testing_salarymean, type="response")
test_maj_rule2 <- ifelse(salarymean_pred_testing > 0.5, 1,0)
calc_error_rate(test_maj_rule2, testing_salarymean$salarygreater)

#Now we can plot an ROC curve for the test data:
pred <- prediction(salarymean_pred_testing, testing_salarymean$salarygreater)

perf <- performance(pred, measure = "tpr", x.measure = "fpr")

plot(perf, col = 2, lwd = 3, main = "ROC curve")

abline(0, 1)

#And calculate the area under the curve (AUC):
auc <- performance(pred, "auc")@y.values[[1]]
auc
```

## Training dataset 80%, testing 20%

```{r}
# Set random seed
set.seed(3112022)

# Sample 80% observations as training data
fit_data <- our_data[-1] 
new_data <- resample_partition(fit_data, p = c(test=0.2, train=0.8)) 
training <- as.data.frame(new_data$train)
testing <- as.data.frame(new_data$test)

x <- model.matrix(Salary~., fit_data)
y <- fit_data$Salary

x.train <- as.matrix(training[,-21])
y.train <- as.matrix(training$Salary)
x.test <- as.matrix(testing[,-21])
y.test <- as.matrix(testing$Salary)
```

## Ridge / Lasso

```{r}
# ridge
lambda.list.ridge = 1000 * exp(seq(0, log(1e-5), length = 100))

ridge.mod = cv.glmnet(x.train, y.train, alpha=0,lambda=lambda.list.ridge, nfolds=5)

ridge.pred_1=predict(ridge.mod, s = ridge.mod$lambda.min, type="coefficients", newx=x.test)

ridge.pred=predict(ridge.mod, s = ridge.mod$lambda.min, newx=x.test)
mean((ridge.pred-y.test)^2)


# cross-validation to choose best tuning parameter
set.seed(3142022)
cv.out.ridge = cv.glmnet(x.train, y.train, alpha= 0)
plot(cv.out.ridge)
abline(v=log(cv.out.ridge$lambda.min), col = "blue", lwd=3, lty=2)

bestlam = cv.out.ridge$lambda.min
bestlam

ridge.pred=predict(ridge.mod, s = bestlam, newx=x.test)
mean((ridge.pred-y.test)^2)

out = glmnet(x,y,alpha=0)
predict(out, type="coefficients", s=bestlam)
```

```{r}
# lasso
set.seed(3142022)
lambda.list.lasso = 2 * exp(seq(0, log(1e-4), length = 100))

lasso.mod <- glmnet(x.train, y.train, alpha=1, lambda=lambda.list.lasso, nfolds = 5)

plot(lasso.mod, xvar="lambda", label=TRUE)

cv.out.lasso = cv.glmnet(x.train,y.train,alpha=1)
plot(cv.out.lasso)
abline(v=log(cv.out.lasso$lambda.min), col="red", lwd=3, lty=2)

bestlam2 = cv.out.lasso$lambda.min
lasso.pred = predict(lasso.mod, s = bestlam2, newx = x.test)
mean((lasso.pred-y.test)^2)

out = glmnet(x, y, alpha=1, lambda=lambda.list.lasso)
lasso.coef = predict(out, type="coefficients", s=bestlam)
lasso.coef

```

## Training dataset 80%, testing 20%

Code for Categorical Decison Tree:
```{r}
# Set random seed
set.seed(3112022)
 
# Sample 80% observations as training data
fit_data <- our_data[-1] 
new_data <- resample_partition(fit_data, p = c(test=0.2, train=0.8)) 
training <- as.data.frame(new_data$train)
testing <- as.data.frame(new_data$test)
high.test = our_data$High
```
 
```{r}
# Create data frame with the oringinal eleven variables and High
our_data = our_data %>%
mutate(High=as.factor(ifelse(Salary <= median(Salary), "No", "Yes")))
```
 
```{r}
glimpse(our_data)
tree_our_data=tree(High~.-Salary,data = our_data) 
```
 
```{r}
summary(tree_our_data)
```
 
```{r}
plot(tree_our_data)
text(tree_our_data, pretty = 0, cex = .4, col = "red")
title("decision tree on Our data", cex = 0.8)
```
 
```{r}
draw.tree(tree_our_data, nodeinfo=TRUE, cex = 0.4)
```
 
```{r}
# Set random seed for results being reproducible
set.seed(3)
# Get dimension of dataset
dim(our_data)
```
 
```{r}
 
# Fit model on training set
tree.nba = tree(High~.-Salary, data = training)
 
# Plot the tree
draw.tree(tree.nba, nodeinfo=TRUE, cex = 0.4)
title("Classification Tree Built on Training Set")
 
```
```{r}
# Predict on test set
tree.pred = predict(tree.nba, test, type="class")
tree.pred
```
```{r}
# Obtain confusion matrix
error = table(tree.nba, high.test)
error
```
```{r}
# Test accuracy rate
sum(diag(error))/sum(error)
```
 
```{r}
# Test error rate (Classification Error)
1-sum(diag(error))/sum(error)
```
 
```{r}
#same thing as above
mean(tree.pred != High.test)
```
 
```{r}
# Set random seed
set.seed(3)
# K=10-Fold cross validation
cv = cv.tree(tree.nba, FUN=prune.misclass, K=10)
# Print out cv
cv$size
```


## random forest

## 
