---
title: "PSTAT131 Final Project"
author: "Joseph Chang, Tom Wei, Akul Bajaj"
date: "3/11/2022"
output:
  html_document:
    code_folding: hide
df_print: paged
---

```{r setup, include=FALSE, echo = FALSE}
# set global chunk options: images will be 7x5 inches
knitr::opts_chunk$set(fig.width=7, fig.height=5, echo =TRUE, message=FALSE, warning = FALSE)
options(digits = 4)
```

## Packages

Here we installed necessary packages

```{r}
#install.packages("tidyverse")
library(ggplot2)                     
library(GGally)
library(tidyverse)
library(glmnet)
library(knitr)
library(dplyr)
library(tidyverse)
library(modelr)
library(pander)
library(corrplot)
library(readxl)
library(ISLR)
library(tidymodels)
library(ggthemes)
library(naniar)
library(ROCR)
library(maptree)
library(tree)
library(factoextra)
library(cluster)
```

# Introduction

After a long nine to five at work, many people across the United States look to unwind with a bottle of beer and one of the world's greatest pastimes, live sports! From October to May we watch basketball stars like Lebron James dropping dimes, or Stephen Curry splashing from threes, but what factors lead these players to such success in the basketball industry, and specifically what factors affect the salaries of NBA players, which can actually range from \$377,645 all the way to \$45,780,966. In our project we use statistical variables such as "PPG", or "Offensive Rating" in different statistical machine learning models to predict the salaries of NBA players in the 2021-2022 season.

Before we dive into the data, the definitions of the variables should be clarified first. All the variables contained in our datasets will be listed below.

PPG: Points per game.

RPG: Rebounds per game.

APG: Assists per game.

SPG: Steals per game.

BPG: Blocks per game.

TPG: Turnovers per game.

MPG: Minutes per game.

Usage Rate: an estimate of the percentage of team plays used by a player while he was on the floor.

Free throw %: Free throw percentage.

Three-point %: Three point shot percentage.

Effective shooting %: a statistic that adjusts field goal percentage to account for the fact that three-point field goals count for three points while field goals only count for two points. Its goal is to show what field goal percentage a two-point shooter would have to shoot at to match the output of a player who also shoots three-pointers.

True shooting %: an advanced statistic that measures a player's efficiency at shooting the ball. It is intended to more accurately calculate a player's shooting than field goal percentage, free throw percentage, and three-point field goal percentage taken individually.

Versatility Index: measures a player's ability to produce in more than one statistic. The metric uses points, assists, and rebounds. The average player will score around a five on the index, while top players score above 10. Calculated by: Versatility Index Formula=[(PPG)\*(RPG)\*APG)]\^(0.333)

Offensive Rating: measures an individual player's efficiency at producing points for the offense.

Defensive rating: measures an individual player's efficiency at preventing the other team from scoring points.

Player Efficiency Rating: a method of determining a player's impact on the game by measuring their per-minute performance. Rather than judging a player solely on their stats, their PER is a much more thorough performance indicator. It details a player and compares their value to that of other players in the league.

Win shares: a player statistic which attempts to divvy up credit for team success to the individuals on the team.

Box Plus Minus: estimates a basketball player's contribution to the team when that player is on the court.

Value Over Replacement: estimates each player's overall contribution to the team, measured vs. what a theoretical "replacement player" would provide, where the "replacement player" is defined as a player on minimum salary or not a normal member of a team's rotation.

## Read data

First, we read in the data that we downloaded. The first dataset is from a website called NBA stuffer, which contains many basketball statistics in an excel file. The second dataset is from kaggle and contains more basketball statistics, some different than the first dataset. The last dataset is from basketball-reference.com and lists out every players' salary in the 2021-2022 season.

```{r}
# NBA stuffer
X2020_2021_NBA_Stats_Player_Box_Score_Advanced_Metrics <- read_excel("2020-2021 NBA Stats  Player Box Score  Advanced Metrics.xlsx")
bball_stats <- as.data.frame(X2020_2021_NBA_Stats_Player_Box_Score_Advanced_Metrics)
my_colnames <- c('Rank', 'Player', 'Team', 'Position', 'Age', 'Games_Played', 'MPG', 'Minutes_percent', 'Usage_Rate' , 'Turnover_rate', 'free_throws_attempted', 'Free_throw_percent', '2-point_field goals_attempted', '2-point_percent', '3-point_field_goals_attempted', 'three_point_percent', 'effective_shooting_percent' , 'True_shooting_percent', 'PPG', 'RPG', 'Total_rebound_percent', 'APG', 'Assist_percent', 'SPG' ,'BPG', 'TPG', 'Versatility_Index', 'Offensive_Rating' , 'Defensive_Rating')
colnames(bball_stats) <- my_colnames
new_bball_stats <- bball_stats[-1,-1]

# kaggle
labels <- c('Player','Position', 'Age', 'Team', 'Games', 'Minutes_played', 'Player_Efficiency_Rating', 'true_shooting_percent', '3-point_attempt_rate', 'free-throw_attempt_rate', 'offensive_rebound_ percentage', 'defensive_rebound_percentage', 'total_rebound_percentage', 'assist_percentage', 'steal_percentage', 'block_percentage', 'turnover_percentage', 'usage_rate', 'offensive_win_shares', 'defensive_win_shares', 'win_shares','win_shares_per_48_minutes', 'Offensive_Box_Plus/Minus', 'Defensive_Box_Plus/Minus','Box_Plus_Minus','Value_Over_Replacement')
data_advanced <- read.csv("nba2021_advanced.csv", col.names = labels, na= "XXX")

# basektball-reference salaries
labels2 <- c('Rank', 'Player', 'Salary', 'Use', 'Guaranteed')
salaries <- read.csv("nba_salaries_21-22.csv", col.names = labels2)
```

## Merge data into "master" dataset

This is where we merge the three datasets into one "master" dataset. This "master" dataset removes duplicated columns as well as columns that show unrelated/insignificant statistics. In addition, this "master" dataset changes all columns (except Player and Salary) to dbl for more convenient use later on. Small remark: a new column called Total_Minutes was added to see if it has any effect on data.

```{r}
combine <- inner_join(new_bball_stats, data_advanced, by = 'Player') %>% 
  inner_join(salaries, by = 'Player')
  
selection <- subset(combine, select= -c(2:4,29:33,35:45,54,56:57)) 
less_data <- selection %>% relocate(c(PPG,RPG,APG,SPG,BPG,TPG), .before = MPG)

conversion <- less_data[,2:35] %>% mutate_if(is.character,as.numeric) %>% mutate(Total_Minutes = Games_Played*MPG)
conversion1 <- conversion %>% add_column(less_data$Player) 
names(conversion1)[names(conversion1) == "less_data$Player"] <- "Player"
conversion2 <- conversion1 %>% relocate((Player), .before = Games_Played)
conversion3 <- conversion2 %>% relocate((Total_Minutes), .before=MPG)
```

## Filter data

Next, we wanted to filter out players who did not see the court often or were injured during the season. Keeping such players otherwise would have skewed the data and produced outliers. Here, players with total minutes less than 336 minutes and less than 7 agmes were taken out. (The entire season consisted of 72 games. 10% of 72 games is around 7 games. A full game is 48 minutes, so 7 full games is 336 minutes). In summary, a player had to play in 90% of the games to be considered. (The previous code was used to reduce columns, here we reduce rows).

```{r}
reduced_data <- conversion3 %>% filter(Games_Played >= 7 & Total_Minutes >= 336) %>% select(Player:Salary) %>% drop_na()
```

## Correlation to Salary

Since there are still a lot of predictors (columns) left, we need a way to only show the important ones. The rest can be omitted. Thus, we used a correlation plot and found correlation coefficients as related to salary.

```{r}
my_cor <- reduced_data %>% select_if(is.numeric) %>% drop_na() %>% cor() %>% round(3) 
corrplot(my_cor, method = "circle", type = "upper", cex.pch=10)

salarycor <- reduced_data %>% select(Salary, Games_Played:Value_Over_Replacement) %>% drop_na()
cor(salarycor)[,"Salary"]
```

Based from the correlation, we will filter those correlations with Salary above 0.6, meaning we will only use PPG, APG, MPG, TPG, Minutes_percent, free_throws_attempted, Offensive_Box_Plus.Minus, Value_Over_Replacement.

## Final dataset and Histograms

This is where we put the final dataset. It has our players, their salaries, and the 8 predictors we want. We will be referring to our_data the rest of the project. As a start to visualize the data, we plotted the response variable Salary using a histogram and the scatter plots of Salary vs. the 8 predictors which has the greatest correlation with salary.

```{r}
our_data <- reduced_data %>% select(Player, Salary, PPG, APG, MPG, TPG, MPG, Minutes_percent, free_throws_attempted, Offensive_Box_Plus.Minus, Value_Over_Replacement)

hist(our_data$Salary, main = "Histogram of NBA salaries 2021-2022", xlab="Salary Amount",breaks = "Sturges", labels = TRUE)

plot(our_data$Salary, our_data$PPG, main="Scatterplot of Salary vs. PPG",
   xlab="Salary", ylab="PPG", pch=19)
plot(our_data$Salary, our_data$APG, main="Scatterplot of Salary vs. APG",
   xlab="Salary", ylab="APG", pch=19)
plot(our_data$Salary, our_data$MPG, main="Scatterplot of Salary vs. MPG",
   xlab="Salary", ylab="MPG", pch=19)
plot(our_data$Salary, our_data$TPG, main="Scatterplot of Salary vs. TPG",
   xlab="Salary", ylab="TPG", pch=19)
plot(our_data$Salary, our_data$Minutes_percent, main="Scatterplot of Salary vs. Minutes Percent",
   xlab="Salary", ylab="Minutes Percent", pch=19)
plot(our_data$Salary, our_data$free_throws_attempted, main="Scatterplot of Salary vs. Free Throws   Attempted",
   xlab="Salary", ylab="Free Throws Attempted", pch=19)
plot(our_data$Salary, our_data$Offensive_Box_Plus.Minus, main="Scatterplot of Salary vs. Offensive Box Plus Minus",
   xlab="Salary", ylab="Offensive Box Plus Minus", pch=19)
plot(our_data$Salary, our_data$Value_Over_Replacement, main="Scatterplot of Salary vs. Value Over Replacement",
   xlab="Salary", ylab="Value Over Replacement", pch=19)
```

## Training and Testing data

In our models we need testing and training datas. Training data will be 80% and testing will be 20%. Here we define them and will proceed with these in mind.

```{r}
set.seed(3112022)
fit_data <- our_data[-1] 
new_data <- resample_partition(fit_data, p = c(test=0.2, train=0.8)) 
training <- as.data.frame(new_data$train)
testing <- as.data.frame(new_data$test)
```

## Linear regression

Our first model is linear regression. There were a total of 3 fitted models. The first model consists of all 9 predictors. Based from the summary of that first fit, the second fit contains only predictors that were significant. Since the first and second fit were closely aligned, the third fit looked at the summary of the first fit and chose more signicant predictors than the second fit. At the end of each fit, I calculated MSE for that respective fit.

```{r}
fit1 <- lm(Salary ~ PPG + APG + MPG + TPG + MPG + Minutes_percent + free_throws_attempted + Offensive_Box_Plus.Minus + Value_Over_Replacement, data = training)
summary(fit1)

train.predict1 <- predict(fit1, training)
test.predict1 <- predict(fit1, testing)
mean((train.predict1-training$Salary)^2)
mean((test.predict1-testing$Salary)^2)


fit2 <- lm(Salary ~ PPG + APG + Value_Over_Replacement, data= training)
summary(fit2)

train.predict2 <- predict(fit2, training)
test.predict2 <- predict(fit2, testing)
mean((train.predict2-training$Salary)^2)
mean((test.predict2-testing$Salary)^2)


fit3 <- lm(Salary ~ APG + Value_Over_Replacement, data= fit_data)
summary(fit3)

train.predict3 <- predict(fit3, training)
test.predict3 <- predict(fit3, testing)
mean((train.predict3-training$Salary)^2)
mean((test.predict3-testing$Salary)^2)
```

Based from the 3 fitted models, I chose the model with the least MSE for training and testing. The first model had the least MSE for both training and testing so I will use fit1. This makes sense as the largest R-squared was fit1.

## Logistic regression

Since all the nine variables we are going to use are numeric variables, and the logistic regression cannot be used to analyze numeric variables, we will create a new predictor called "salarygreater". "Salarygreater" tests whether a player's salary is greater than the average salary of the league. By producing this new binomial predictor, we can use logistic regression to analyze the salary condition of the players in a new perspective.

First, we will calculate the average salary of all players, and create the new binary variable "salarygreater" in the training dataset to test whether a certain player's salary is greater than the average. If the player's salary is greater than the average, it will show "1" in the "salarygreater"; if not, it will show "0".

```{r}
mean_train_salary <- mean(training$Salary)
training_salarymean<- training %>% mutate(salarygreater=factor(ifelse(Salary >= mean_train_salary, 1, 0), levels=c(0, 1)))
```

Next, we will fit a logistic regression on the "salarygreater" in the training dataset. After that, we will predict based on the "majority rule": if the predicted probability is greater than 0.5, classify the observation as 1, otherwise, classify it as 0.

```{r}
training_logit <- glm(salarygreater ~ PPG + APG + MPG + TPG + Minutes_percent + free_throws_attempted + Offensive_Box_Plus.Minus + Value_Over_Replacement, data = training_salarymean, family = 'binomial')

salarymean_pred_training <- predict(training_logit, training_salarymean, type="response")
train_maj_rule <- ifelse(salarymean_pred_training > 0.5, 1,0)
```

After that, we will define a function called "calc_error_rate" and use it to calculate the error rate of the of the logistic model on the training dataset, which is created above.

```{r}
calc_error_rate <- function(predicted.value, true.value){
  return(mean(true.value!=predicted.value))}
calc_error_rate(train_maj_rule, training_salarymean$salarygreater)
```

Similary, we will do the same process on the testing dataset to predict based on the logistic model created above and calculate the test error.

```{r}
testing_salarymean<- testing %>% mutate(salarygreater=factor(ifelse(Salary >= mean_train_salary, 1, 0), levels=c(0, 1)))
salarymean_pred_testing <- predict(training_logit,  testing_salarymean, type="response")
test_maj_rule2 <- ifelse(salarymean_pred_testing > 0.5, 1,0)
calc_error_rate(test_maj_rule2, testing_salarymean$salarygreater)
```

Finally, we can plot an ROC curve and calculate the area under the curve (AUC) for the test data to see the performance of the logistic regression model.

```{r}
pred <- prediction(salarymean_pred_testing, testing_salarymean$salarygreater)
perf <- performance(pred, measure = "tpr", x.measure = "fpr")
plot(perf, col = 2, lwd = 3, main = "ROC curve")
abline(0, 1)
```

AUC is shown below.

```{r}
auc <- performance(pred, "auc")@y.values[[1]]
auc
```

## Training, Testing for Ridge/ Lasso

```{r}
x <- model.matrix(Salary~., fit_data)
y <- fit_data$Salary

x.train <- as.matrix(training[,-1])
y.train <- as.matrix(training$Salary)
x.test <- as.matrix(testing[,-1])
y.test <- as.matrix(testing$Salary)
```

## Ridge / Lasso

```{r}
# ridge
lambda.list.ridge = 1000 * exp(seq(0, log(1e-5), length = 100))

ridge.mod = cv.glmnet(x.train, y.train, alpha=0,lambda=lambda.list.ridge, nfolds=5)

ridge.pred_1=predict(ridge.mod, s = ridge.mod$lambda.min, type="coefficients", newx=x.test)

ridge.pred=predict(ridge.mod, s = ridge.mod$lambda.min, newx=x.test)
mean((ridge.pred-y.test)^2)


# cross-validation to choose best tuning parameter
set.seed(3142022)
cv.out.ridge = cv.glmnet(x.train, y.train, alpha= 0)
plot(cv.out.ridge)
abline(v=log(cv.out.ridge$lambda.min), col = "blue", lwd=3, lty=2)

bestlam = cv.out.ridge$lambda.min
bestlam

ridge.pred=predict(ridge.mod, s = bestlam, newx=x.test)
mean((ridge.pred-y.test)^2)

out = glmnet(x,y,alpha=0)
predict(out, type="coefficients", s=bestlam)
```

```{r}
# lasso
set.seed(3142022)
lambda.list.lasso = 2 * exp(seq(0, log(1e-4), length = 100))

lasso.mod <- glmnet(x.train, y.train, alpha=1, lambda=lambda.list.lasso, nfolds = 5)

plot(lasso.mod, xvar="lambda", label=TRUE)

cv.out.lasso = cv.glmnet(x.train,y.train,alpha=1)
plot(cv.out.lasso)
abline(v=log(cv.out.lasso$lambda.min), col="red", lwd=3, lty=2)

bestlam2 = cv.out.lasso$lambda.min
lasso.pred = predict(lasso.mod, s = bestlam2, newx = x.test)
mean((lasso.pred-y.test)^2)

out = glmnet(x, y, alpha=1, lambda=lambda.list.lasso)
lasso.coef = predict(out, type="coefficients", s=bestlam)
lasso.coef

```



## Regression Decision Tree:

Here, we start by using the tree() function to create a decision tree using our_data. Then we take a summary of this tree to see variables used in tree construction, number of terminal nodes, and residual information.

```{r}
tree_our_data=tree(Salary~. , data = our_data) 
summary(tree_our_data)
```

Here we plot our decision tree using two different tree plotting functions, plot and draw tree. Both trees have 7 terminal nodes.

```{r}
# plot the fitted tree
plot(tree_our_data)
text(tree_our_data, pretty = 0, cex = .4, col = "blue")
title("Decision tree on our_data", cex = 0.8)
```

```{r}
draw.tree(tree_our_data, nodeinfo=TRUE, cex = 0.4)
```

Furthermore, we fit the regression decision tree model to the training set and plot the tree using the draw.tree() command.

```{r}
# Fit model on training set
tree.nba = tree(Salary~. , data = training)
 
# Plot the tree
draw.tree(tree.nba, nodeinfo=TRUE, cex = 0.4)
title("Regression Tree Built on Training Set")
```

We can see in the summary that the tree modeled by the training set has 10 terminal nodes, whereas the previous tree had 12 terminal nodes.

```{r}
summary(tree.nba)
```

Now here we do a prediction on the test set using the predict() command. We specify type='vector' because we are working with a regression decision tree. Then we calculate the mean squared error which is 6.68e+13 and root mean squared error which is 8173153.

```{r}
# Predict on test set
tree.pred = predict(tree.nba, testing, type="vector")
tree.pred

# mean squared error
y = mean((tree.pred-testing$Salary)^2)
y
# root mean squared error
z=sqrt(y)
z
```

To calculate the best number of terminal nodes we do a 10-fold cross validation. We plot size versus cross-validation error rate and add a vertical line at the minimum error. From this we can see 9 is the ideal number of terminal nodes, because he error is the lowest at that point.

```{r}
set.seed(3142022)

#K=10-Fold cross validation
cv = cv.tree(tree.nba, K=10)

# the tree with smaller size
best.cv = min(cv$size[cv$dev == min(cv$dev)])
best.cv

# Plot size vs. cross-validation error rate
 plot(cv$size , cv$dev, type="b", xlab = "Number of leaves, \'best\'",
      ylab = "CV Misclassification Error", col = "red", main="CV")
 abline(v=best.cv, lty=2)

# Add lines to identify complexity parameter
min.error = which.min(cv$dev) # Get minimum error index
abline(h = cv$dev[min.error],lty = 2)
```

We can now plot the pruned tree with 9 terminal nodes. The mean squared error (MSE) is lowest when the number of terminal nodes is 9.

```{r}
# Prune tree
pt.cv = prune.tree(tree.nba, best=best.cv)

# # Plot pruned tree
plot(pt.cv)
text(pt.cv, pretty=0, col = "blue", cex = .5)
title("Pruned tree of size")
```

```{r}
# Calculate the respective test error rate for the model

# Predict on test set
pred.pt.cv = predict(pt.cv, testing, type="vector")
 
# # examine misclassification errors on training set
# print('training errors')
# classes_test <- as.data.frame(testing) %>% pull(High)
# train_errors_topt <- table(class = classes_test, pred = pred.pt.cv)
# train_errors_topt/rowSums(train_errors_topt)

# test error rate for pt.cv for pt.cv is 0.27907

# The MSE is lower with 7 nodes (8047525). So best. ???
```


## random forest

## PCA

```{r}
dat <- our_data %>% select(-1)
summary(dat)

# check variance of each variable in our_data
apply(dat, 2, var)

# Principle component Analysis
pr.out = prcomp(dat, scale = TRUE)
# center is the mean and scale is the standard deviation
pr.out$center
pr.out$scale
pr.out$rotation

# plot 
biplot(pr.out, scale = 0)

# number of prinicipal components needed
pr.out$sdev
pr.var = pr.out$sdev^2
pr.var
pve = pr.var/sum(pr.var)
pve

# plot 
plot(pve, xlab = "Principal Component", ylab = "Proportion of Variance Explained", ylim = c(0,1), type = "b")
plot(cumsum(pve), xlab=  "Principal Component", ylab = "Cumulative Proportion of Variance Explained", ylim=c(0,1), type= "b")

# we will consider the first two PCAs because they are the largest 2 values. 
```

## Cluster

```{r}
scar  = scale(dat, center=TRUE, scale=TRUE)
km = kmeans(scar, centers=2)
km
fviz_cluster(km, data= dat, gemo= "point", stand = FALSE, frame.type = "norm")

# Dim 1 is more influential. cluster 2 is skewed right

# centering the winner data so we can find out the loadings for the first two PCs

# data_svd <- svd(scar)
# data_loadings <- data_svd$v[,1:2]
# data_pc <- as.matrix(scar) %*% data_loadings 
# colnames(data_loadings) <- colnames(data_pc) <- paste('PC', 1:2, sep = '')
# 
# Player <- our_data$Player %>% factor()
# 
# data_pc %>%
#   as.data.frame() %>%
#   #bind_cols((dplyr:: select(data, state, county, candidate))) %>%
#   ggplot(aes(x = PC1, y = PC2)) +
#   geom_point(alpha = 0.5, aes(color = Player)) +
#   theme_bw()
```

# Conclusion
